# Defining data folder structure
folder_structure:
  #data_root_folder: &BASE ./data
  data_root_folder: &BASE /media/sz/Data/Connected_Lecturers/LiaScript
  raw_data_folder: &RAW !join [*BASE, /raw]
  file_folder: &FILE_FOLDER !join [*RAW, /files]
  content_folder: &CONTENT_FOLDER !join [*RAW, /content]
  processed_data_folder: &PREPROCESSED !join [*BASE, /processed]

# Global LLM Configuration (can be overridden in individual stages)
global_llm_config: &LLM_CONFIG
  base_url: "http://localhost:11434"
  embedding_model: "jina/jina-embeddings-v2-base-de"
  collection_name: "liascript_courses"
  timeout_seconds: 240
  chroma_db_folder: "chroma_db"  # ChromaDB database folder

# Global Logging Configuration
logging:
  configure_root_logger: false  # Whether to configure the root logger
  root_level: "ERROR"          # Level for root logger (if enabled)
  pipeline_level: "INFO"       # Level for pipeline-specific loggers

  # External logger configuration (overrides default values)
  external_loggers:
    # HTTP and network - set to CRITICAL for less noise
    httpcore: "CRITICAL"
    "httpcore.http11": "CRITICAL"
    httpx: "CRITICAL"
    urllib3: "CRITICAL"
    "urllib3.connectionpool": "CRITICAL"
    requests: "CRITICAL"

    # LangChain and AI - set to WARNING for important messages
    langchain: "WARNING"
    langchain_ollama: "WARNING"
    "langchain_text_splitters.base": "ERROR"
    ollama: "WARNING"

    # Image processing - set to WARNING
    PIL: "WARNING"
    "PIL.PngImagePlugin": "WARNING"

    # Unstructured - set to CRITICAL for less noise
    "unstructured.trace": "CRITICAL"

# Referencing the modules containing classes
stages_module_path:
    - ../stages/general/
    - ../stages/liascript/
    - ../stages/opal/

# Defining stages and parameters
stages:
  - name: Generate data folder structure
    class: ProvideDataFolders

  - name: Identify LiaScript repositories
    class: CrawlGithubForLiaScript
    parameters:
      repo_data_file_name: &REPOSITORIES_DF LiaScript_repositories.p
      force_run: False
      #internal: ['LiaScript','TUBAF-IfI-LiaScript','LiaPlayground','SebastianZug','andre-dietrich','LiaBooks','LiaTemplates','TUBAF-IUZ-LiaScript','markjjacob','HueblerPatricia']

  - name: Aggregate LiaScript files
    class: AggregateLiaScriptFiles
    parameters:
      repo_data_file_name_input: *REPOSITORIES_DF
      lia_files_name: &LIAFILES_DF LiaScript_files.p
      force_run: True

      # Optional: Exclude specific repository indices from processing
      exclude_repo_indices:
        - 439
        - 481
        - 497

  - name: Validate LiaScript files with AI
    class: ValidateLiaScriptFiles
    parameters:
      file_name_input: *LIAFILES_DF
      file_name_output: &LIAFILES_VALIDATED_DF LiaScript_files_validated.p
      force_run: True
      model_name: llama3.3:70b
      max_content_length: 8000  # Characters to send to AI for validation
      validate_all: False  # Only validate files without validation result

      # LLM Configuration
      llm_config: *LLM_CONFIG

  - name: Aggregate LiaScript commits
    class: AggregateLiaScriptCommits
    parameters:
      lia_files_name_input: *LIAFILES_VALIDATED_DF
      lia_commits_name: &LIACOMMITS_DF LiaScript_commits.p
      force_run: True

  - name: Extract LiaScript metadata from headers
    class: ExtractLiaScriptMetadata
    parameters:
      lia_files_name_input: *LIAFILES_VALIDATED_DF
      lia_metadata_name: &LIAMETADATA_DF LiaScript_metadata.p
      force_run: True

  - name: Extract content from markdown files
    class: ExtractFileContent
    parameters:
      file_name_input: *LIAFILES_VALIDATED_DF
      file_name_output: &LIASCONTENT_DF LiaScript_content.p
      force_run: True
      file_types: ['md']

  - name: Provide embeddings
    class: AIEmbeddingsGeneration
    parameters:
      file_name_input: *LIAFILES_VALIDATED_DF
      file_name_output: &LIACHROMAFILES LiaScript_embeddings_files.p
      force_run: True
      file_types: ['md']

      # LLM and Vector Store Configuration
      llm_config: *LLM_CONFIG

  - name: Extract AI metadata from content
    class: AIMetaDataExtraction
    parameters:
      file_name_input: *LIAFILES_VALIDATED_DF
      file_name_output: &LIAAIMETA LiaScript_ai_meta.p
      prompts_file_name: pipelines/liascript/prompts/prompts.yaml
      dewey_classification_file: dewey_classification.txt
      model_name: llama3.3:70b
      force_run: True
      file_types: ['md']

      # LLM and Vector Store Configuration
      llm_config: *LLM_CONFIG

      # Processing mode configuration
      processing_mode:
        # Force processing: These fields are ALWAYS processed (overwrite existing data)
        force_processing: []    # Empty list = no force processing

        # Conditional processing: These fields are only processed if empty/missing
        conditional_processing:
          - ai:author
          - ai:keywords_gen
          - ai:title
          - ai:type
          - ai:keywords_ext
          - ai:summary
          - ai:dewey

        # Skip configuration: Skip file if NO conditional fields need processing
        allow_skip_when_all_conditional_filled: false  # Enable skipping when all fields are filled

  - name: Check Keywords with GND
    class: GNDKeywordCheck
    parameters:
      file_name_input: *LIAAIMETA
      file_name_output: &LIAKEYWORDS LiaScript_checked_keywords.p
      force_run: True
      use_llm: true         # KI-basierte Schlagwortauswahl aktivieren
      llm_model: "gemma3:27b"  # Ollama-Modell für Schlagwortauswahl
      use_full_keyword_context: true  # Alle Keywords eines Dokuments als Kontext verwenden
      use_document_metadata: true     # Zusätzliche Dokumentmetadaten als Kontext einbeziehen

  - name: Determine similarity between courses
    class: DocumentSimilarity
    parameters:
      file_name_input: *LIAFILES_VALIDATED_DF
      file_name_output: &LIASIMILARITY LiaScript_ai_similarity.p
      force_run: True

      # Vector Store Configuration
      llm_config:
        collection_name: "liascript_courses"